{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb201502-c30e-4b78-b438-b60f562003cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extenstion of notebook 3 and 4\n",
    "-- Actually 2.2.0 tagged version https://github.com/pyg-team/pytorch_geometric/tree/2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce98ca37-386f-41d6-9444-82fb622a04ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epedersen/.pyenv/versions/3.8.12/envs/torch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "print(torch.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# note it uses the wrong linkNeighborLoader (there are two). one for sampler and one for loader.\n",
    "from torch_geometric.loader import LinkNeighborLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56d6ed2b-e9f2-431d-8d90-4962394ea000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "# we actually doen't need this if we just use hetero data, also have graph_store interface. \n",
    "def add_date_to_graph_store(graph_store,data):\n",
    "    for edge_type in train_data.edge_types: \n",
    "        edge_index = data[edge_type].edge_index\n",
    "        coo = (edge_index[0], edge_index[1])\n",
    "        graph_store_train.put_edge_index(edge_index = coo,\n",
    "                            edge_type = edge_type,\n",
    "                            layout = 'coo',\n",
    "                            size = (feature_store[edge_type[0]].num_nodes, feature_store[edge_type[2]].num_nodes)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d2ec56-cc6c-41ee-ad41-a8f9e3601c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file ml-latest-small.zip\n",
      "Extracting ./ml-latest-small.zip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "extract_zip(download_url(url, '.'), '.')\n",
    "\n",
    "movies_path = './ml-latest-small/movies.csv'\n",
    "ratings_path = './ml-latest-small/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b6e7f1-b6b2-4809-96ed-fb941b56cae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.csv:\n",
      "===========\n",
      "   movieId                                       genres\n",
      "0        1  Adventure|Animation|Children|Comedy|Fantasy\n",
      "1        2                   Adventure|Children|Fantasy\n",
      "2        3                               Comedy|Romance\n",
      "3        4                         Comedy|Drama|Romance\n",
      "4        5                                       Comedy\n",
      "\n",
      "ratings.csv:\n",
      "============\n",
      "   userId  movieId\n",
      "0       1        1\n",
      "1       1        3\n",
      "2       1        6\n",
      "3       1       47\n",
      "4       1       50\n"
     ]
    }
   ],
   "source": [
    "print('movies.csv:')\n",
    "print('===========')\n",
    "print(pd.read_csv(movies_path)[[\"movieId\", \"genres\"]].head())\n",
    "print()\n",
    "print('ratings.csv:')\n",
    "print('============')\n",
    "print(pd.read_csv(ratings_path)[[\"userId\", \"movieId\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d69a799a-7fd7-4c49-af3b-d9f6188edcbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Action  Adventure  Drama  Horror\n",
      "movieId                                  \n",
      "1             0          1      0       0\n",
      "2             0          1      0       0\n",
      "3             0          0      0       0\n",
      "4             0          0      1       0\n",
      "5             0          0      0       0\n"
     ]
    }
   ],
   "source": [
    "# Load the entire movie data frame into memory:\n",
    "movies_df = pd.read_csv(movies_path, index_col='movieId')\n",
    "\n",
    "# Split genres and convert into indicator variables:\n",
    "genres = movies_df['genres'].str.get_dummies('|')\n",
    "print(genres[[\"Action\", \"Adventure\", \"Drama\", \"Horror\"]].head())\n",
    "\n",
    "# Use genres as movie input features:\n",
    "movie_feat = torch.from_numpy(genres.values).to(torch.float)\n",
    "assert movie_feat.size() == (9742, 20)  # 20 genres in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea3f4d4-3e7b-4818-bc7d-59a41484a3da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of user IDs to consecutive values:\n",
      "==========================================\n",
      "   userId  mappedID\n",
      "0       1         0\n",
      "1       2         1\n",
      "2       3         2\n",
      "3       4         3\n",
      "4       5         4\n",
      "\n",
      "Mapping of movie IDs to consecutive values:\n",
      "===========================================\n",
      "   movieId  mappedID\n",
      "0        1         0\n",
      "1        3         1\n",
      "2        6         2\n",
      "3       47         3\n",
      "4       50         4\n",
      "\n",
      "Final edge indices pointing from users to movies:\n",
      "=================================================\n",
      "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
      "        [   0,    1,    2,  ..., 3121, 1392, 2873]])\n"
     ]
    }
   ],
   "source": [
    "# Load the entire ratings data frame into memory:\n",
    "ratings_df = pd.read_csv(ratings_path)\n",
    "\n",
    "# Create a mapping from unique user indices to range [0, num_user_nodes):\n",
    "unique_user_id = ratings_df['userId'].unique()\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'userId': unique_user_id,\n",
    "    'mappedID': pd.RangeIndex(len(unique_user_id)),\n",
    "})\n",
    "print(\"Mapping of user IDs to consecutive values:\")\n",
    "print(\"==========================================\")\n",
    "print(unique_user_id.head())\n",
    "print()\n",
    "# Create a mapping from unique movie indices to range [0, num_movie_nodes):\n",
    "unique_movie_id = ratings_df['movieId'].unique()\n",
    "unique_movie_id = pd.DataFrame(data={\n",
    "    'movieId': unique_movie_id,\n",
    "    'mappedID': pd.RangeIndex(len(unique_movie_id)),\n",
    "})\n",
    "print(\"Mapping of movie IDs to consecutive values:\")\n",
    "print(\"===========================================\")\n",
    "print(unique_movie_id.head())\n",
    "\n",
    "# Perform merge to obtain the edges from users and movies:\n",
    "ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id,\n",
    "                            left_on='userId', right_on='userId', how='left')\n",
    "ratings_user_id = torch.from_numpy(ratings_user_id['mappedID'].values)\n",
    "ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id,\n",
    "                            left_on='movieId', right_on='movieId', how='left')\n",
    "ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedID'].values)\n",
    "\n",
    "# With this, we are ready to construct our `edge_index` in COO format\n",
    "# following PyG semantics:\n",
    "edge_index_user_to_movie = torch.stack([ratings_user_id, ratings_movie_id], dim=0)\n",
    "assert edge_index_user_to_movie.size() == (2, 100836)\n",
    "\n",
    "print()\n",
    "print(\"Final edge indices pointing from users to movies:\")\n",
    "print(\"=================================================\")\n",
    "print(edge_index_user_to_movie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e9f26-0f1d-4cad-be2e-757534db9a51",
   "metadata": {},
   "source": [
    "### Create random user links as well \n",
    "(we want to work with multiple link types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e53165bd-deef-4e50-9bef-4988437b8558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[581,  77,  32, 314,  26, 418, 556,  31, 395, 317,  38,  50, 363, 132,\n",
       "         185, 463, 600, 538, 156, 596, 527, 371,  94, 314, 140, 339, 531, 414,\n",
       "         115, 344, 243, 175,  28,  56, 157, 123,  93,   1, 510, 157, 142, 294,\n",
       "         585, 578, 119, 117, 512, 340, 437, 541, 241, 198, 542, 367, 263,  15,\n",
       "         100, 119, 589, 603, 357, 334, 551, 438, 260, 599, 219, 177, 499, 279,\n",
       "         591,  72, 530, 343, 165, 493, 154, 251, 401, 278, 421, 490, 530, 564,\n",
       "         558, 142, 387,  76, 114, 498, 419, 480, 415, 192, 116, 342, 526, 420,\n",
       "         608, 173],\n",
       "        [474, 307, 351,  49, 393, 563, 379, 463,  84, 278, 571, 130, 341, 605,\n",
       "          68,   0, 381, 551, 403, 574,  99, 110, 488, 239, 118, 146, 375,  11,\n",
       "         140, 114,  10, 481,  28, 292,  30,   3,  55, 560, 428,  32, 191, 155,\n",
       "         227, 408, 296, 269,  50, 527, 558, 342,  31,  49, 371, 215, 375, 133,\n",
       "         211,  64, 442, 576, 523, 435, 275, 341, 364, 515, 474, 536, 561, 108,\n",
       "         196, 263,  19, 219, 459, 311,  56, 530, 584, 599, 109, 125,  96, 515,\n",
       "          83,  90,  85, 117, 560, 512,   0, 311, 447,  42, 275, 536,   1,  45,\n",
       "         430, 187]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "user_to_user = np.random.choice(unique_user_id.mappedID.values, size=(100,2), replace=True, p=None)\n",
    "\n",
    "edge_index_user_to_user = torch.stack((torch.from_numpy(user_to_user[:,0])\n",
    "                                    ,torch.from_numpy(user_to_user[:,1])),dim=0)\n",
    "edge_index_user_to_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7245cee-903a-4457-8ab6-8fcd756ff9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1muser\u001b[0m={ node_id=[610] },\n",
      "  \u001b[1mmovie\u001b[0m={ node_id=[9742] },\n",
      "  \u001b[1m(user, rates, movie)\u001b[0m={ edge_index=[2, 100836] },\n",
      "  \u001b[1m(user, likes, user)\u001b[0m={ edge_index=[2, 199] },\n",
      "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 100836] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = HeteroData()\n",
    "\n",
    "## Keep data object to only transform it to the graph store after transformation\n",
    "## but omit adding the feature vectors of movies.\n",
    "# Save node indices:\n",
    "data[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
    "data[\"movie\"].node_id = torch.arange(len(movies_df))\n",
    "\n",
    "# Add the node features and edge indices:\n",
    "# data[\"movie\"].x = movie_feat # TODO\n",
    "data[\"user\", \"rates\", \"movie\"].edge_index = edge_index_user_to_movie  \n",
    "data[\"user\", \"likes\", \"user\"].edge_index = edge_index_user_to_user \n",
    "\n",
    "# We also need to make sure to add the reverse edges from movies to users\n",
    "# in order to let a GNN be able to pass messages in both directions.\n",
    "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
    "\n",
    "# TODO:\n",
    "# FROM HERE https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html\n",
    "transform = T.Compose([T.ToUndirected()])\n",
    "data = transform(data)          \n",
    "\n",
    "feature_store = HeteroData()\n",
    "\n",
    "# Add the data to the feature store\n",
    "feature_store.put_tensor(movie_feat, group_name='movie', attr_name='x', index=torch.arange(len(movies_df)))\n",
    "feature_store.put_tensor(torch.arange(len(movies_df)), group_name='movie', attr_name='node_id', index=torch.arange(len(movies_df)))\n",
    "\n",
    "\n",
    "# TODO: Is there a way to add a feature with only id to the feature store? \n",
    "feature_store.put_tensor(torch.arange(len(unique_user_id)),group_name='user', attr_name='node_id', index=torch.arange(len(unique_user_id)))\n",
    "\n",
    "\n",
    "## Delay adding graph to graph store after linksplits \n",
    "## Add graph to graph store\n",
    "\n",
    "#graph_store = HeteroData()\n",
    "# coo = (edge_index_user_to_movie[0], edge_index_user_to_movie[1])\n",
    "\n",
    "# graph_store.put_edge_index(edge_index=coo,\n",
    "#                            edge_type=('user', 'rates', 'movie'),\n",
    "#                            layout='coo', size=(len(coo[0]),len(coo[1])) )\n",
    "\n",
    "# # put reverse index\n",
    "# graph_store.put_edge_index(edge_index=coo[::-1],\n",
    "#                            edge_type=('movie', 'rev_rates', 'user'),\n",
    "#                            layout='coo', size=(len(coo[1]),len(coo[0])) )\n",
    "\n",
    "\n",
    "print(data)\n",
    "\n",
    "assert data.node_types == [\"user\", \"movie\"]\n",
    "assert data.edge_types == [(\"user\", \"rates\", \"movie\"),\n",
    "                           (\"user\",\"likes\",\"user\"),\n",
    "                           (\"movie\", \"rev_rates\", \"user\"),\n",
    "                           ]\n",
    "assert data[\"user\"].num_nodes == 610\n",
    "assert data[\"user\"].num_features == 0\n",
    "assert data[\"movie\"].num_nodes == 9742\n",
    "#assert data[\"movie\"].num_features == 20\n",
    "assert data[\"user\", \"rates\", \"movie\"].num_edges == 100836\n",
    "assert data[\"movie\", \"rev_rates\", \"user\"].num_edges == 100836\n",
    "#assert data[\"user\", \"likes\", \"user\"].num_edges == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa32fbba-7159-4665-aff3-a56aa450e460",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "==============\n",
      "HeteroData(\n",
      "  \u001b[1muser\u001b[0m={ node_id=[610] },\n",
      "  \u001b[1mmovie\u001b[0m={ node_id=[9742] },\n",
      "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
      "    edge_index=[2, 56469],\n",
      "    edge_label=[24201],\n",
      "    edge_label_index=[2, 24201]\n",
      "  },\n",
      "  \u001b[1m(user, likes, user)\u001b[0m={\n",
      "    edge_index=[2, 113],\n",
      "    edge_label=[48],\n",
      "    edge_label_index=[2, 48]\n",
      "  },\n",
      "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 56469] }\n",
      ")\n",
      "\n",
      "Validation data:\n",
      "================\n",
      "HeteroData(\n",
      "  \u001b[1muser\u001b[0m={ node_id=[610] },\n",
      "  \u001b[1mmovie\u001b[0m={ node_id=[9742] },\n",
      "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
      "    edge_index=[2, 80670],\n",
      "    edge_label=[30249],\n",
      "    edge_label_index=[2, 30249]\n",
      "  },\n",
      "  \u001b[1m(user, likes, user)\u001b[0m={\n",
      "    edge_index=[2, 161],\n",
      "    edge_label=[57],\n",
      "    edge_label_index=[2, 57]\n",
      "  },\n",
      "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 80670] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1, \n",
    "    num_test=0.1,  \n",
    "    disjoint_train_ratio=.3,  \n",
    "    neg_sampling_ratio=2,  \n",
    "    add_negative_train_samples=False,  \n",
    "    edge_types=[(\"user\", \"rates\", \"movie\"),(\"user\",\"likes\",\"user\")],\n",
    "    rev_edge_types=[(\"movie\", \"rev_rates\", \"user\"),(\"user\",\"likes\",\"user\")], \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(\"Training data:\")\n",
    "print(\"==============\")\n",
    "print(train_data)\n",
    "print()\n",
    "print(\"Validation data:\")\n",
    "print(\"================\")\n",
    "print(val_data)\n",
    "\n",
    "\n",
    "## Not needed. The data itself can work as the graph store. \n",
    "# train_graph_store = HeteroData()\n",
    "# add_date_to_graph_store(train_graph_store, train_data)\n",
    "\n",
    "\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].num_edges == 56469\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 24201\n",
    "assert train_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 56469\n",
    "# No negative edges added:\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 1\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1\n",
    "\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].num_edges == 80670\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 30249\n",
    "assert val_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 80670\n",
    "# Negative edges with ratio 2:1:\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].edge_label.long().bincount().tolist() == [20166, 10083]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01bdb5a8-286a-4fbb-ae43-1a3328d5cf1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define seed edges:\n",
    "edge_label_index = train_data[(\"user\", \"rates\", \"movie\")].edge_label_index\n",
    "edge_label = train_data[(\"user\", \"rates\", \"movie\")].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb30648-b0f2-4141-8a4c-0b76fff439f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled mini-batch:\n",
      "===================\n",
      "HeteroData(\n",
      "  \u001b[1mmovie\u001b[0m={\n",
      "    num_nodes=2750,\n",
      "    x=[2750, 20],\n",
      "    node_id=[2750]\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={\n",
      "    num_nodes=604,\n",
      "    node_id=[604]\n",
      "  },\n",
      "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
      "    edge_index=[2, 17251],\n",
      "    input_id=[128],\n",
      "    edge_label_index=[2, 384],\n",
      "    edge_label=[384]\n",
      "  },\n",
      "  \u001b[1m(user, likes, user)\u001b[0m={ edge_index=[2, 104] },\n",
      "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 7784] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Sample only with labels for user_rate_movies\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=(feature_store,train_data),  # <--- Changed to feature store, graph store\n",
    "    num_neighbors=[20,10],  # Original [20,10]\n",
    "    neg_sampling_ratio=2,  \n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128, # Original 128\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Inspect a sample:\n",
    "sampled_data = next(iter(train_loader))\n",
    "\n",
    "print(\"Sampled mini-batch:\")\n",
    "print(\"===================\")\n",
    "print(sampled_data)\n",
    "\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 3 * 128\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 0\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac75d1a9-38f2-419b-b2a9-aec377184c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_edge_label_index = train_data[(\"user\", \"likes\", \"user\")].edge_label_index\n",
    "user_edge_label = train_data[(\"user\", \"likes\", \"user\")].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5390f896-50a5-4940-98a5-32a98bf5b15c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled mini-batch:\n",
      "===================\n",
      "HeteroData(\n",
      "  \u001b[1mmovie\u001b[0m={\n",
      "    num_nodes=1831,\n",
      "    x=[1831, 20],\n",
      "    node_id=[1831]\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={\n",
      "    num_nodes=604,\n",
      "    node_id=[604]\n",
      "  },\n",
      "  \u001b[1m(user, rates, movie)\u001b[0m={ edge_index=[2, 13777] },\n",
      "  \u001b[1m(user, likes, user)\u001b[0m={\n",
      "    edge_index=[2, 81],\n",
      "    input_id=[48],\n",
      "    edge_label_index=[2, 144],\n",
      "    edge_label=[144]\n",
      "  },\n",
      "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 4410] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# sample only for user_likes_user\n",
    "\n",
    "# Sample only with labels for user_rate_movies\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=(feature_store,train_data),  # <--- Changed to feature store, graph store\n",
    "    num_neighbors=[20,10],  # Original [20,10]\n",
    "    neg_sampling_ratio=2,  \n",
    "    edge_label_index=((\"user\",\"likes\",\"user\"),user_edge_label_index),\n",
    "    edge_label=user_edge_label,\n",
    "    batch_size=128, # Original 128\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Inspect a sample:\n",
    "sampled_data = next(iter(train_loader))\n",
    "\n",
    "print(\"Sampled mini-batch:\")\n",
    "print(\"===================\")\n",
    "print(sampled_data)\n",
    "\n",
    "# assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 3 * 128\n",
    "# assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 0\n",
    "# assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bcecf-c4eb-471d-8d5d-6658af1b7f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
